---
layout: post
category: "machinelearning"
title:  "keras"
tags: [python, machine learning]
---

## 概述

Keras: means horn in Greek。用python编写的，是高层的封装器，可以调用不同的后台，比如tensorflow，CNTK，Theano。目的就是为了更快的构建机器学习模型。

## 基本概念

基本的数据结构：`model`，构建网络层用的。最简单的模型是`Sequential`，线性堆叠的层。

### 构建模型

定义`Sequential`模型：

```python
from keras.models import Sequential

model = Sequential()
```

添加层`.add()`：

```python
from keras.layers import Dense

model.add(Dense(units=64, activation='relu', input_dim=100))
model.add(Dense(units=10, activation='softmax'))
```

`keras`的一个核心就是[`Dense`函数](https://keras.io/zh/layers/core/)，用于构建全连接层，其实现的操作是`output = activation(dot(input, kernel) + bias)`，全部参数如下：

```python
keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)


```

- units: 正整数，**输出空间维度[不是输入]**。
- activation: 激活函数。若不指定，则不使用激活函数 (即，「线性」激活: a(x) = x)。
- use_bias: 布尔值，该层是否使用偏置向量。
- kernel_initializer: kernel 权值矩阵的初始化器。
- bias_initializer: 偏置向量的初始化器.
- kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数。
- bias_regularizer: 运用到偏置项的的正则化函数。
- activity_regularizer: 运用到层的输出的正则化函数 (它的 "activation")。
- kernel_constraint: 运用到 kernel 权值矩阵的约束函数。
- bias_constraint: 运用到偏置向量的约束函数。

使用例子，第一层显示指定输入的大小尺寸，必须和feed的数据的feature数目相同，否则无法导入数据：

```python
# 作为 Sequential 模型的第一层
model = Sequential()
model.add(Dense(32, input_shape=(16,)))
# 现在模型就会以尺寸为 (*, 16) 的数组作为输入，
# 其输出数组的尺寸为 (*, 32)

# 在第一层之后，你就不再需要指定输入的尺寸了：
model.add(Dense(32))
```

### 编译模型 

基于网络编译模型`.compile()`，编译模型函数`.compile()`包含3个参数：

 - 优化器（optimizer）：已定义的优化器名称或者类对象
 - 损失函数（loss）：已定义的损失函数名称或者自定义的损失函数
 - 指标列表（metric）：对于分类问题，一般设为`[accuracy]`

```python
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])
```

在构建模型时刻自定义loss函数，优化函数的参数等：

```python
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))
```

### 训练模型：

```python
# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.
model.fit(x_train, y_train, epochs=5, batch_size=32)

# 手动batch训练
model.train_on_batch(x_batch, y_batch)
```

### 评估模型

```python
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

预测新数据：

```python
classes = model.predict(x_test, batch_size=128)
```

## 示例：Multilayer Perceptron (MLP) for multi-class softmax classification

```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate dummy data
import numpy as np
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)
x_test = np.random.random((100, 20))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)

model = Sequential()
# Dense(64) is a fully-connected layer with 64 hidden units.
# in the first layer, you must specify the expected input data shape:
# here, 20-dimensional vectors.
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=20,
          batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
```

## cheatsheet

[![keras_cheatsheet.png](https://i.loli.net/2019/05/15/5cdbb6cb0067534410.png)](https://i.loli.net/2019/05/15/5cdbb6cb0067534410.png)

## 参考

* [keras @ github](https://github.com/keras-team/keras)
* [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/)
* [快速开始序贯（Sequential）模型](https://keras-cn.readthedocs.io/en/latest/getting_started/sequential_model/)
* [keras-cheat-sheet](https://www.datacamp.com/community/blog/keras-cheat-sheet)




